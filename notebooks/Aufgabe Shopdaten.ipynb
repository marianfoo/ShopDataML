{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten importieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transact_train   = Transaktionsdaten zum trainieren\n",
    "- transact_class   = aktuelle Transaktionsdaten zum testen\n",
    "- realclass_t1     = \"Lösung\" der transact_class ob Käufer oder nicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transact_train = pd.read_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/transact_train.txt', sep='|', na_values='?')\n",
    "transact_class = pd.read_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/transact_class.txt', sep='|', na_values='?')\n",
    "realclass_t1 = pd.read_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/realclass_t1.txt', sep='|', na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifizierung der Testdaten an Testdaten anhängen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "transact_class = pd.merge(transact_class, realclass_t1, on='sessionNo').rename(columns={'prediction': 'order'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduzierung der Trainingsdaten falls notwendig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_size_data(factor, df):\n",
    "    print('Shape of dataframe before down sizing with factor' + str(factor) +':' + str(df.shape))\n",
    "    sampleSize = int(len(df.index) * factor)\n",
    "    df = df.sample(sampleSize)\n",
    "    print('Shape of dataframe after down sizing with factor' + str(factor) + ':' + str(df.shape))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe before down sizing with factor0.01:(429013, 24)\n",
      "Shape of dataframe after down sizing with factor0.01:(4290, 24)\n"
     ]
    }
   ],
   "source": [
    "transact_train = down_size_data(0llll.01,transact_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten des Typs 'String' in integer umwandeln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_values(df):\n",
    "    if df['order'].dtype == 'object':\n",
    "        df['order'] = df['order'].map({'y': 1, 'n': 0})\n",
    "    df['onlineStatus'] = df['onlineStatus'].map({'y': 1, 'n': 0})\n",
    "    df['availability'] = df['availability'].map({\n",
    "        'completely orderable': 1, 'completely not orderable': 2, 'mainly orderable': 3,\n",
    "        'mixed': 4, 'completely not determinable': 5, 'mainly not orderable': 6, 'mainly not determinable': 7\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_values(transact_train)\n",
    "mapping_values(transact_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kundennr. hat keine Relevanz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transact_train.drop('customerNo', axis=1, inplace=True)\n",
    "transact_class.drop('customerNo', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spalte 'sessionNo' als Index für Dataframe nutzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transact_train.set_index('sessionNo', inplace=True)\n",
    "transact_class.set_index('sessionNo', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neue Daten aus den vorhanden Spalten erzeugen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leere Spalten erzeugen zum füllen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def add_columns(copy):\n",
    "    df = copy.copy()\n",
    "    df['maxBStep'] = np.nan\n",
    "    df['avgBStep'] = np.nan\n",
    "    df['countTransact'] = np.nan\n",
    "    df['maxAvailability'] = np.nan\n",
    "    df['maxOnlineStatus'] = np.nan\n",
    "    df['avgAvailability'] = np.nan\n",
    "    df['minOnlineStatus'] = np.nan\n",
    "    df['minAvailability'] = np.nan\n",
    "    # sicherstellen das order in der letzten Spalte ist\n",
    "    df = df.reindex(columns=(list([a for a in df.columns if a != 'order']) + ['order'] ))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transact_train = add_columns(transact_train)\n",
    "transact_class = add_columns(transact_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_columns(added_df):\n",
    "    # Serie erzeugen mit allen unique Session Nummern\n",
    "    unique_sessions = added_df.index.unique().sort_values()\n",
    "    # Loop durch alle Session Nummern [1,2,3,4,....]\n",
    "    for session in unique_sessions:\n",
    "        if session % 1000 == 0:\n",
    "            print(str(session))\n",
    "        # Alle Zeilen mit der Session Nummer\n",
    "        rows = added_df.loc[added_df.index == session]\n",
    "        # Maximale Nummer Schritt in der Einkaufsabwicklung\n",
    "        maxBStep = rows['bStep'].max()\n",
    "        # Durchschn. Nummer Schritt in der Einkaufsabwicklung\n",
    "        avgBStep = rows['bStep'].mean()\n",
    "        # Anzahl der Transaktionen der Sessionnr.\n",
    "        countTransact = len(rows.index)\n",
    "        # Max. Zahl der Produktsverfügbarkeit\n",
    "        maxAvailability = rows['availability'].max()\n",
    "        # Min. Zahl der Produktsverfügbarkeit\n",
    "        minAvailability = rows['availability'].min()\n",
    "        # Durchschn. Zahl der Produktsverfügbarkeit\n",
    "        avgAvailability = rows['availability'].mean()\n",
    "        # Max. Zahl der Online Status (0 oder 1)\n",
    "        maxOnlineStatus = rows['onlineStatus'].max()\n",
    "        # Min. Zahl der Online Status (0 oder 1)\n",
    "        minOnlineStatus = rows['onlineStatus'].min()\n",
    "        added_df.loc[added_df.index == session,'maxBStep'] = maxBStep\n",
    "        added_df.loc[added_df.index == session,'avgBStep'] = avgBStep\n",
    "        added_df.loc[added_df.index == session,'countTransact'] = countTransact\n",
    "        added_df.loc[added_df.index == session,'maxAvailability'] = maxAvailability\n",
    "        added_df.loc[added_df.index == session,'minAvailability'] = minAvailability\n",
    "        added_df.loc[added_df.index == session,'avgAvailability'] = avgAvailability\n",
    "        added_df.loc[added_df.index == session,'maxOnlineStatus'] = maxOnlineStatus\n",
    "        added_df.loc[added_df.index == session,'minOnlineStatus'] = minOnlineStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "14000\n",
      "42000\n",
      "50000\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "fill_columns(transact_train)\n",
    "fill_columns(transact_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leere Zeilen mit verschiedene Zahlen füllen\n",
    "## mean = Mittelwert der jeweiligen Spalte\n",
    "## median = Median der jeweiligen Spalte\n",
    "## mode = Modi der einzelnen Elemente entlang der ausgewählten Achse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null_values(df, mode):\n",
    "    if mode == 'mean':\n",
    "        df = df.fillna(value=df.mean())\n",
    "        print('Filled null values with mean')\n",
    "    if mode == 'median':\n",
    "        df = df.fillna(value=df.median())\n",
    "        print('Filled null values with median')\n",
    "    if mode == 'mode':\n",
    "        df = df.fillna(value=df.mode().iloc[0])\n",
    "        print('Filled null values with mode')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Für Traingsdaten und Testdaten wird für die jeweiligen Modus eine eigener Dataframe erzeugt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled null values with mean\n",
      "Filled null values with median\n",
      "Filled null values with mode\n",
      "Filled null values with mean\n",
      "Filled null values with median\n",
      "Filled null values with mode\n"
     ]
    }
   ],
   "source": [
    "train_mean = fill_null_values(transact_train, 'mean')\n",
    "train_median = fill_null_values(transact_train, 'median')\n",
    "train_mode = fill_null_values(transact_train, 'mode')\n",
    "class_mean = fill_null_values(transact_class, 'mean')\n",
    "class_median = fill_null_values(transact_class, 'median')\n",
    "class_mode = fill_null_values(transact_class, 'mode')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wegen des langen Prozess werden die Daten in CSVs gespeichert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean.to_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/train_mean_small.csv')\n",
    "train_median.to_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/train_median_small.csv')\n",
    "train_mode.to_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/train_mode_small.csv')\n",
    "class_mean.to_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/class_mean_small.csv')\n",
    "class_median.to_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/class_median_small.csv')\n",
    "class_mode.to_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/class_mode_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fertig vearbeitete Daten importien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_small = pd.read_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/train_mean_small.csv')\n",
    "class_mean_small = pd.read_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/class_mean_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index = sessionNo was not saved to csv, have to do it again\n",
    "train_mean_small.set_index('sessionNo', inplace=True)\n",
    "class_mean_small.set_index('sessionNo', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_small.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make sure test and training data is same shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(train_df,test_df):\n",
    "    X_train = train_df.iloc[:, :train_df.shape[1] - 1]\n",
    "    X_test = test_df.iloc[:, :test_df.shape[1] - 1]\n",
    "    y_train = train_df['order']\n",
    "    y_test  = test_df['order']\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data_2(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.set_index('sessionNo', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "def get_all_data():\n",
    "    columns_data = ['X_train_','X_test_','y_train_','y_test_']\n",
    "    fill_modes = ['mean','mode','median']\n",
    "    column_count = [5,10,15,20]\n",
    "    new_dict = {}\n",
    "\n",
    "    for fill_mode in fill_modes:\n",
    "        for count in column_count:\n",
    "            filename_base = '~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/'\n",
    "            filename_2 = filename_base + 'train' + '_' + fill_mode + '_' + str(count) + '.csv'\n",
    "            train_file = import_data_2(filename_2)\n",
    "            filename_2 = filename_base + 'class' + '_' + fill_mode + '_' + str(count) + '.csv'\n",
    "            class_file = import_data_2(filename_2)\n",
    "            X_train, X_test, y_train, y_test = get_test_data(train_file,class_file)\n",
    "            new_dict[fill_mode + '_' + str(count)] = {\n",
    "                'X_train':X_train,\n",
    "                'X_test':X_test,\n",
    "                'y_train':y_train,\n",
    "                'y_test':y_test\n",
    "            }\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection with RFE and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe, X_test_rfe, y_train_rfe, y_test_rfe = get_test_data(train_mean_small,class_mean_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select_rfe(X_train_rfe,y_train_rfe,iterations,attributes):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.feature_selection import RFE\n",
    "    logistic_reg_rfe = LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=iterations)\n",
    "    rfe = RFE(logistic_reg_rfe, attributes)\n",
    "    rfe = rfe.fit(X_train_rfe, y_train_rfe)\n",
    "    # summarize the selection of the attributes\n",
    "    print(\"Num Features: %d\" % rfe.n_features_)\n",
    "    print(\"Selected Features: %s\" % rfe.support_)\n",
    "    print(\"Feature Ranking: %s\" % rfe.ranking_)\n",
    "    return rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropBadColumns (df,rfe):\n",
    "    df_copy = df.copy()\n",
    "    dropArray = []\n",
    "    keepArray = []\n",
    "    for index in range(len(rfe.ranking_)):\n",
    "        if rfe.ranking_[index] != 1:\n",
    "            dropArray.append(index)\n",
    "        else:\n",
    "            keepArray.append(index)\n",
    "\n",
    "    print('Columns to keep: {}'.format(list(df_copy.columns[keepArray])))\n",
    "    print('Columns to discard: {}'.format(list(df_copy.columns[dropArray])))\n",
    "    df_copy.drop(df_copy.columns[dropArray], axis=1,  inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use these moduls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 10\n",
      "Selected Features: [False False False False False False False  True False False False False\n",
      " False  True False False False False False False False  True  True  True\n",
      "  True  True  True  True  True]\n",
      "Feature Ranking: [ 4  3 17  7  9 20 16  1 11 10 18  5 12  1 19 14  8 15  6  2 13  1  1  1\n",
      "  1  1  1  1  1]\n",
      "Columns to keep: ['bCount', 'availability', 'maxBStep', 'avgBStep', 'countTransact', 'maxAvailability', 'maxOnlineStatus', 'avgAvailability', 'minOnlineStatus', 'minAvailability']\n",
      "Columns to discard: ['startHour', 'startWeekday', 'duration', 'cCount', 'cMinPrice', 'cMaxPrice', 'cSumPrice', 'bMinPrice', 'bMaxPrice', 'bSumPrice', 'bStep', 'onlineStatus', 'maxVal', 'customerScore', 'accountLifetime', 'payments', 'age', 'address', 'lastOrder']\n",
      "Columns to keep: ['bCount', 'availability', 'maxBStep', 'avgBStep', 'countTransact', 'maxAvailability', 'maxOnlineStatus', 'avgAvailability', 'minOnlineStatus', 'minAvailability']\n",
      "Columns to discard: ['startHour', 'startWeekday', 'duration', 'cCount', 'cMinPrice', 'cMaxPrice', 'cSumPrice', 'bMinPrice', 'bMaxPrice', 'bSumPrice', 'bStep', 'onlineStatus', 'maxVal', 'customerScore', 'accountLifetime', 'payments', 'age', 'address', 'lastOrder']\n"
     ]
    }
   ],
   "source": [
    "rfe = feature_select_rfe(X_train_rfe,y_train_rfe,1000,10)  \n",
    "X_train_rfe_dropped = dropBadColumns(X_train_rfe,rfe)  \n",
    "X_test_rfe_dropped  = dropBadColumns(X_test_rfe,rfe)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare feature selection in advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_select_rfe_feature(X_train_rfe,y_train_rfe,iterations,attributes):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.feature_selection import RFE\n",
    "    logistic_reg_rfe = LogisticRegression(solver='lbfgs',multi_class='auto',max_iter=iterations)\n",
    "    rfe = RFE(logistic_reg_rfe, attributes)\n",
    "    rfe = rfe.fit(X_train_rfe, y_train_rfe)\n",
    "    # summarize the selection of the attributes\n",
    "    print(\"Num Features: %d\" % rfe.n_features_)\n",
    "    print(\"Selected Features: %s\" % rfe.support_)\n",
    "    print(\"Feature Ranking: %s\" % rfe.ranking_)\n",
    "    return rfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropBadColumns_feature (df,rfe):\n",
    "    df_copy = df.copy()\n",
    "    dropArray = []\n",
    "    keepArray = []\n",
    "    for index in range(len(rfe.ranking_)):\n",
    "        if rfe.ranking_[index] != 1:\n",
    "            dropArray.append(index)\n",
    "        else:\n",
    "            keepArray.append(index)\n",
    "\n",
    "    print('Columns to keep: {}'.format(list(df_copy.columns[keepArray])))\n",
    "    print('Columns to discard: {}'.format(list(df_copy.columns[dropArray])))\n",
    "    df_copy.drop(df_copy.columns[dropArray], axis=1,  inplace=True)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_feature(train_df):\n",
    "    X_train = train_df.iloc[:, :train_df.shape[1] - 1]\n",
    "    y_train = train_df['order']\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = import_data('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/train_mean.csv')\n",
    "train_mean_5_rfe = feature_select_rfe(X_train_mean,y_train_mean,5000,5)\n",
    "train_mean_5 = dropBadColumns(train_mean,train_mean_5_rfe)\n",
    "train_mean_5.to_csv('~/Google Drive/Studium/StrategischeSysteme/DMC2013/data/train_mean_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'train_mean_5_rfe.sav'\n",
    "joblib.dump(train_mean_5_rfe, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance with Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_etr, X_test_etr, y_train_etr, y_test_etr = get_test_data(train_mean_small,class_mean_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "extra_tree_model = ExtraTreesClassifier(n_estimators=100)\n",
    "extra_tree_model.fit(X_train_etr, y_train_etr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction with Univariate Statistical Tests (Chi-squared for classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_chi, X_test_chi, y_train_chi, y_test_chi = get_test_data(train_mean_small,class_mean_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.21197069e+01 5.74364339e-01 2.66399246e+04 1.44160771e+03\n",
      " 3.61802442e+04 2.37000164e+04 8.85553060e+04 5.99450867e+02\n",
      " 3.64564409e+04 2.11912899e+04 7.05382728e+03 3.43824189e+01\n",
      " 1.14630503e-01 2.10478622e+00 2.07972852e+04 7.93352864e+01\n",
      " 9.31610310e+02 2.56634152e+02 1.91034114e+00 1.73479193e-01\n",
      " 2.20895970e+02 3.93466648e+01 3.71276495e+01 3.91890897e+00\n",
      " 1.84073035e+00 1.25543659e-01 1.92245845e+00 1.40134301e-01\n",
      " 1.90887751e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "feature_sel_kbest_model = SelectKBest(score_func=chi2, k=3)\n",
    "feature_sel_kbest_fit = feature_sel_kbest_model.fit(X_train_chi,  y_train_chi)\n",
    "# summarize scores\n",
    "print(feature_sel_kbest_fit.scores_)\n",
    "features = feature_sel_kbest_fit.transform(X_train_chi)\n",
    "# summarize selected features\n",
    "# print(features[0:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summarize all feature selection in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Support</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Feature Importances</th>\n",
       "      <th>Fit Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>maxOnlineStatus</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minOnlineStatus</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxAvailability</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgAvailability</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minAvailability</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007484</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007306</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>countTransact</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017596</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avgBStep</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020965</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxBStep</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018591</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bCount</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0.055586</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.059764</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>startWeekday</th>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>startHour</th>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.063364</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bStep</th>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0.031421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cCount</th>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>0.060252</td>\n",
       "      <td>1441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accountLifetime</th>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>0.039543</td>\n",
       "      <td>931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cMinPrice</th>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>0.058310</td>\n",
       "      <td>36180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bMaxPrice</th>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>0.055535</td>\n",
       "      <td>21191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bMinPrice</th>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>0.059589</td>\n",
       "      <td>36456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onlineStatus</th>\n",
       "      <td>False</td>\n",
       "      <td>12</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lastOrder</th>\n",
       "      <td>False</td>\n",
       "      <td>13</td>\n",
       "      <td>0.032103</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customerScore</th>\n",
       "      <td>False</td>\n",
       "      <td>14</td>\n",
       "      <td>0.035052</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payments</th>\n",
       "      <td>False</td>\n",
       "      <td>15</td>\n",
       "      <td>0.028217</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cSumPrice</th>\n",
       "      <td>False</td>\n",
       "      <td>16</td>\n",
       "      <td>0.056230</td>\n",
       "      <td>88555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>False</td>\n",
       "      <td>17</td>\n",
       "      <td>0.061034</td>\n",
       "      <td>26639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bSumPrice</th>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>0.056056</td>\n",
       "      <td>7053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxVal</th>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>0.030898</td>\n",
       "      <td>20797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cMaxPrice</th>\n",
       "      <td>False</td>\n",
       "      <td>20</td>\n",
       "      <td>0.055648</td>\n",
       "      <td>23700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Support  Ranking  Feature Importances  Fit Scores\n",
       "maxOnlineStatus     True        1             0.006043           0\n",
       "minOnlineStatus     True        1             0.006020           0\n",
       "maxAvailability     True        1             0.007661           1\n",
       "avgAvailability     True        1             0.007716           1\n",
       "minAvailability     True        1             0.007484           1\n",
       "availability        True        1             0.007306           2\n",
       "countTransact       True        1             0.017596           3\n",
       "avgBStep            True        1             0.020965          37\n",
       "maxBStep            True        1             0.018591          39\n",
       "bCount              True        1             0.055586         599\n",
       "address            False        2             0.059764           0\n",
       "startWeekday       False        3             0.037162           0\n",
       "startHour          False        4             0.063364          32\n",
       "bStep              False        5             0.019394          34\n",
       "age                False        6             0.031421           1\n",
       "cCount             False        7             0.060252        1441\n",
       "accountLifetime    False        8             0.039543         931\n",
       "cMinPrice          False        9             0.058310       36180\n",
       "bMaxPrice          False       10             0.055535       21191\n",
       "bMinPrice          False       11             0.059589       36456\n",
       "onlineStatus       False       12             0.005460           0\n",
       "lastOrder          False       13             0.032103         220\n",
       "customerScore      False       14             0.035052          79\n",
       "payments           False       15             0.028217         256\n",
       "cSumPrice          False       16             0.056230       88555\n",
       "duration           False       17             0.061034       26639\n",
       "bSumPrice          False       18             0.056056        7053\n",
       "maxVal             False       19             0.030898       20797\n",
       "cMaxPrice          False       20             0.055648       23700"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_select_pd = pd.DataFrame(\n",
    "    data={'Support': rfe.support_, 'Ranking': rfe.ranking_, 'Feature Importances': extra_tree_model.feature_importances_,\n",
    "          'Fit Scores': feature_sel_kbest_fit.scores_}, index=list(train_mean_small.iloc[:, :train_mean_small.shape[1] - 1]))\n",
    "feature_select_pd['Fit Scores'] = feature_select_pd['Fit Scores'].astype('int64')\n",
    "feature_select_pd.sort_values(by=['Ranking', 'Fit Scores'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "feature_select_objects = feature_select_pd.index.values\n",
    "y_pos = np.arange(len(feature_select_objects))\n",
    "performance = feature_select_pd['Ranking'].sort_values(ascending=False)\n",
    "\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.yticks(y_pos, feature_select_objects)\n",
    "plt.xlabel('Ranking')\n",
    "plt.title('Feature selection results')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INSERT HERE COLUMN SELECTION FOR MODEL TRAINING AND PREDICTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_knn, X_test_knn, y_train_knn, y_test_knn = get_test_data(train_mean_small,class_mean_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_knn = StandardScaler()\n",
    "scaler.fit(X_train_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "scaled_features_knn = scaler_knn.transform(X_train_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startHour</th>\n",
       "      <th>startWeekday</th>\n",
       "      <th>duration</th>\n",
       "      <th>cCount</th>\n",
       "      <th>cMinPrice</th>\n",
       "      <th>cMaxPrice</th>\n",
       "      <th>cSumPrice</th>\n",
       "      <th>bCount</th>\n",
       "      <th>bMinPrice</th>\n",
       "      <th>bMaxPrice</th>\n",
       "      <th>...</th>\n",
       "      <th>address</th>\n",
       "      <th>lastOrder</th>\n",
       "      <th>maxBStep</th>\n",
       "      <th>avgBStep</th>\n",
       "      <th>countTransact</th>\n",
       "      <th>maxAvailability</th>\n",
       "      <th>maxOnlineStatus</th>\n",
       "      <th>avgAvailability</th>\n",
       "      <th>minOnlineStatus</th>\n",
       "      <th>minAvailability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.904625</td>\n",
       "      <td>-1.185052</td>\n",
       "      <td>-0.578670</td>\n",
       "      <td>-0.594483</td>\n",
       "      <td>-0.197264</td>\n",
       "      <td>-0.429769</td>\n",
       "      <td>-0.395658</td>\n",
       "      <td>-0.488625</td>\n",
       "      <td>-0.242715</td>\n",
       "      <td>-0.382288</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.028271e+00</td>\n",
       "      <td>-4.747563e-01</td>\n",
       "      <td>-4.387137e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.368511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187741e-15</td>\n",
       "      <td>5.412535e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.904625</td>\n",
       "      <td>-1.185052</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>0.093238</td>\n",
       "      <td>-0.302832</td>\n",
       "      <td>-0.277605</td>\n",
       "      <td>0.084401</td>\n",
       "      <td>-0.488625</td>\n",
       "      <td>-0.336864</td>\n",
       "      <td>-0.199352</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.204054e-16</td>\n",
       "      <td>1.459013e-16</td>\n",
       "      <td>-3.279653e-01</td>\n",
       "      <td>-0.285869</td>\n",
       "      <td>-0.368511</td>\n",
       "      <td>-0.245812</td>\n",
       "      <td>0.135518</td>\n",
       "      <td>-0.238812</td>\n",
       "      <td>1.455540e-01</td>\n",
       "      <td>-2.233789e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.904625</td>\n",
       "      <td>-1.185052</td>\n",
       "      <td>-0.233970</td>\n",
       "      <td>-0.627231</td>\n",
       "      <td>-0.302772</td>\n",
       "      <td>-0.456849</td>\n",
       "      <td>-0.409212</td>\n",
       "      <td>-0.719332</td>\n",
       "      <td>-0.284097</td>\n",
       "      <td>-0.417186</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.204054e-16</td>\n",
       "      <td>1.459013e-16</td>\n",
       "      <td>-4.387137e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.368511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187741e-15</td>\n",
       "      <td>5.412535e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.904625</td>\n",
       "      <td>-1.185052</td>\n",
       "      <td>-0.331706</td>\n",
       "      <td>0.027741</td>\n",
       "      <td>-0.214169</td>\n",
       "      <td>-0.250043</td>\n",
       "      <td>-0.176583</td>\n",
       "      <td>-0.257918</td>\n",
       "      <td>-0.257792</td>\n",
       "      <td>-0.328319</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657862e-01</td>\n",
       "      <td>4.176145e+00</td>\n",
       "      <td>-4.387137e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.368511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187741e-15</td>\n",
       "      <td>5.412535e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.904625</td>\n",
       "      <td>-1.185052</td>\n",
       "      <td>-0.642856</td>\n",
       "      <td>-0.725477</td>\n",
       "      <td>-0.320564</td>\n",
       "      <td>-0.501729</td>\n",
       "      <td>-0.431934</td>\n",
       "      <td>-0.719332</td>\n",
       "      <td>-0.352678</td>\n",
       "      <td>-0.475023</td>\n",
       "      <td>...</td>\n",
       "      <td>7.657862e-01</td>\n",
       "      <td>-7.622292e-01</td>\n",
       "      <td>-4.387137e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.368511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.187741e-15</td>\n",
       "      <td>5.412535e-16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   startHour  startWeekday  duration    cCount  cMinPrice  cMaxPrice  \\\n",
       "0  -1.904625     -1.185052 -0.578670 -0.594483  -0.197264  -0.429769   \n",
       "1  -1.904625     -1.185052  0.017922  0.093238  -0.302832  -0.277605   \n",
       "2  -1.904625     -1.185052 -0.233970 -0.627231  -0.302772  -0.456849   \n",
       "3  -1.904625     -1.185052 -0.331706  0.027741  -0.214169  -0.250043   \n",
       "4  -1.904625     -1.185052 -0.642856 -0.725477  -0.320564  -0.501729   \n",
       "\n",
       "   cSumPrice    bCount  bMinPrice  bMaxPrice       ...              address  \\\n",
       "0  -0.395658 -0.488625  -0.242715  -0.382288       ...        -2.028271e+00   \n",
       "1   0.084401 -0.488625  -0.336864  -0.199352       ...        -6.204054e-16   \n",
       "2  -0.409212 -0.719332  -0.284097  -0.417186       ...        -6.204054e-16   \n",
       "3  -0.176583 -0.257918  -0.257792  -0.328319       ...         7.657862e-01   \n",
       "4  -0.431934 -0.719332  -0.352678  -0.475023       ...         7.657862e-01   \n",
       "\n",
       "      lastOrder      maxBStep  avgBStep  countTransact  maxAvailability  \\\n",
       "0 -4.747563e-01 -4.387137e-16  0.000000      -0.368511         0.000000   \n",
       "1  1.459013e-16 -3.279653e-01 -0.285869      -0.368511        -0.245812   \n",
       "2  1.459013e-16 -4.387137e-16  0.000000      -0.368511         0.000000   \n",
       "3  4.176145e+00 -4.387137e-16  0.000000      -0.368511         0.000000   \n",
       "4 -7.622292e-01 -4.387137e-16  0.000000      -0.368511         0.000000   \n",
       "\n",
       "   maxOnlineStatus  avgAvailability  minOnlineStatus  minAvailability  \n",
       "0         0.000000         0.000000     1.187741e-15     5.412535e-16  \n",
       "1         0.135518        -0.238812     1.455540e-01    -2.233789e-01  \n",
       "2         0.000000         0.000000     1.187741e-15     5.412535e-16  \n",
       "3         0.000000         0.000000     1.187741e-15     5.412535e-16  \n",
       "4         0.000000         0.000000     1.187741e-15     5.412535e-16  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_knn_feat = pd.DataFrame(scaled_features_knn,columns=X_train_knn.columns)\n",
    "X_train_knn_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log_knn = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sessionNo\n",
       "1       1\n",
       "1       1\n",
       "1       1\n",
       "1       1\n",
       "1       1\n",
       "1       1\n",
       "1       1\n",
       "1       1\n",
       "1       1\n",
       "2       1\n",
       "2       1\n",
       "2       1\n",
       "2       1\n",
       "2       1\n",
       "2       1\n",
       "2       1\n",
       "2       1\n",
       "2       1\n",
       "2       1\n",
       "2       1\n",
       "3       1\n",
       "3       1\n",
       "3       1\n",
       "3       1\n",
       "3       1\n",
       "3       1\n",
       "3       1\n",
       "3       1\n",
       "3       1\n",
       "3       1\n",
       "       ..\n",
       "5108    0\n",
       "5108    0\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5109    1\n",
       "5110    0\n",
       "5110    0\n",
       "5110    0\n",
       "5110    0\n",
       "5110    0\n",
       "5110    0\n",
       "5111    0\n",
       "5111    0\n",
       "5111    0\n",
       "5111    0\n",
       "5111    0\n",
       "5111    0\n",
       "5111    0\n",
       "Name: order, Length: 45068, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_log_knn['median_20']['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7e685e186713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mknn_model_median_20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_log_knn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'median_20'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_log_knn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'median_20'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprediction_knn_median_20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_model_median_20\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_log_knn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'median_20'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mperformance_knn_median_20\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_log_knn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'median_20'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_log_knn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'median_20'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model_median_20 = KNeighborsClassifier(n_neighbors=23)\n",
    "knn_model_median_20.fit(data_log_knn['median_20']['X_train'], data_log_knn['median_20']['y_train'])\n",
    "prediction_knn_median_20 = knn_model_median_20.predict(data_log_knn['median_20']['X_train'])\n",
    "performance_knn_median_20 = value[0].score(data_log_knn['median_20']['X_test'], data_log_knn['median_20']['y_test'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_knn_median_20 = knn_model_median_20.score(data_log_knn['median_20']['X_test'], data_log_knn['median_20']['y_test'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.40170409159492"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_knn_median_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startHour</th>\n",
       "      <th>startWeekday</th>\n",
       "      <th>cCount</th>\n",
       "      <th>bCount</th>\n",
       "      <th>bMaxPrice</th>\n",
       "      <th>bStep</th>\n",
       "      <th>onlineStatus</th>\n",
       "      <th>availability</th>\n",
       "      <th>payments</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>lastOrder</th>\n",
       "      <th>maxBStep</th>\n",
       "      <th>avgBStep</th>\n",
       "      <th>countTransact</th>\n",
       "      <th>maxAvailability</th>\n",
       "      <th>maxOnlineStatus</th>\n",
       "      <th>avgAvailability</th>\n",
       "      <th>minOnlineStatus</th>\n",
       "      <th>minAvailability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sessionNo</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>39.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>39.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>39.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>39.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>39.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>39.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>39.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>22.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>9</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>39.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.051282</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.051282</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.99</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.99</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.99</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.99</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.833333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45068 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           startHour  startWeekday  cCount  bCount  bMaxPrice  bStep  \\\n",
       "sessionNo                                                              \n",
       "1                 18             7       3       1      39.99    2.0   \n",
       "1                 18             7       3       1      39.99    2.0   \n",
       "1                 18             7       6       2      39.99    2.0   \n",
       "1                 18             7       8       3      39.99    2.0   \n",
       "1                 18             7      10       4      39.99    2.0   \n",
       "1                 18             7      10       4      39.99    1.0   \n",
       "1                 18             7      11       5      39.99    2.0   \n",
       "1                 18             7      11       5      39.99    1.0   \n",
       "1                 18             7      11       5      39.99    2.0   \n",
       "2                 18             7       7       1      34.99    2.0   \n",
       "2                 18             7       7       1      34.99    2.0   \n",
       "2                 18             7       7       1      34.99    2.0   \n",
       "2                 18             7       7       1      34.99    4.0   \n",
       "2                 18             7       7       1      34.99    2.0   \n",
       "2                 18             7       7       1      34.99    4.0   \n",
       "2                 18             7       7       1      34.99    2.0   \n",
       "2                 18             7      16       2      34.99    2.0   \n",
       "2                 18             7      16       2      34.99    2.0   \n",
       "2                 18             7      16       2      34.99    4.0   \n",
       "2                 18             7      16       2      34.99    2.0   \n",
       "3                 18             7       3       1      17.99    2.0   \n",
       "3                 18             7       7       2      22.99    2.0   \n",
       "3                 18             7      24       3      39.95    2.0   \n",
       "3                 18             7      27       4      39.95    2.0   \n",
       "3                 18             7      44       5      39.95    2.0   \n",
       "3                 18             7      47       6      39.95    2.0   \n",
       "3                 18             7      62       7      39.95    2.0   \n",
       "3                 18             7      67       8      39.95    2.0   \n",
       "3                 18             7      76       9      39.95    2.0   \n",
       "3                 18             7      78      10      39.95    2.0   \n",
       "...              ...           ...     ...     ...        ...    ...   \n",
       "5108               5             1       1       1       6.99    2.0   \n",
       "5108               5             1       1       1       6.99    2.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    5.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    2.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    4.0   \n",
       "5109               5             1       0       0      34.99    5.0   \n",
       "5110               5             1       1       1      49.99    2.0   \n",
       "5110               5             1       1       1      49.99    1.0   \n",
       "5110               5             1       1       1      49.99    2.0   \n",
       "5110               5             1       1       1      49.99    3.0   \n",
       "5110               5             1       1       1      49.99    4.0   \n",
       "5110               5             1       1       1      49.99    5.0   \n",
       "5111               5             1       3       1       4.99    2.0   \n",
       "5111               5             1       3       1       4.99    2.0   \n",
       "5111               5             1       3       1       4.99    3.0   \n",
       "5111               5             1       3       1       4.99    4.0   \n",
       "5111               5             1       3       1       4.99    5.0   \n",
       "5111               5             1       3       1       4.99    4.0   \n",
       "5111               5             1       3       1       4.99    5.0   \n",
       "\n",
       "           onlineStatus  availability  payments   age  address  lastOrder  \\\n",
       "sessionNo                                                                   \n",
       "1                   1.0           1.0       5.0  49.0      1.0       65.0   \n",
       "1                   1.0           1.0       5.0  49.0      1.0       65.0   \n",
       "1                   1.0           1.0       5.0  49.0      1.0       65.0   \n",
       "1                   1.0           1.0       5.0  49.0      1.0       65.0   \n",
       "1                   1.0           1.0       5.0  49.0      1.0       65.0   \n",
       "1                   1.0           1.0       5.0  49.0      1.0       65.0   \n",
       "1                   1.0           1.0       5.0  49.0      1.0       65.0   \n",
       "1                   1.0           1.0       5.0  49.0      1.0       65.0   \n",
       "1                   1.0           1.0       5.0  49.0      1.0       65.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "2                   1.0           1.0       5.0  29.0      2.0      184.0   \n",
       "3                   1.0           1.0       4.0  37.0      2.0      107.0   \n",
       "3                   1.0           1.0       4.0  37.0      2.0      107.0   \n",
       "3                   1.0           1.0       4.0  37.0      2.0      107.0   \n",
       "3                   1.0           1.0       4.0  37.0      2.0      107.0   \n",
       "3                   1.0           1.0       4.0  37.0      2.0      107.0   \n",
       "3                   1.0           1.0       4.0  37.0      2.0      107.0   \n",
       "3                   1.0           1.0       4.0  37.0      2.0      107.0   \n",
       "3                   1.0           1.0       4.0  37.0      2.0      107.0   \n",
       "3                   1.0           1.0       4.0  37.0      2.0      107.0   \n",
       "3                   1.0           1.0       4.0  37.0      2.0      107.0   \n",
       "...                 ...           ...       ...   ...      ...        ...   \n",
       "5108                1.0           1.0       0.0  53.0      1.0       34.0   \n",
       "5108                1.0           1.0       0.0  53.0      1.0       34.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5109                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5110                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5110                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5110                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5110                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5110                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5110                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5111                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5111                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5111                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5111                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5111                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5111                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "5111                1.0           1.0       7.0  43.0      2.0       42.0   \n",
       "\n",
       "           maxBStep  avgBStep  countTransact  maxAvailability  \\\n",
       "sessionNo                                                       \n",
       "1               2.0  1.333333            9.0              1.0   \n",
       "1               2.0  1.333333            9.0              1.0   \n",
       "1               2.0  1.333333            9.0              1.0   \n",
       "1               2.0  1.333333            9.0              1.0   \n",
       "1               2.0  1.333333            9.0              1.0   \n",
       "1               2.0  1.333333            9.0              1.0   \n",
       "1               2.0  1.333333            9.0              1.0   \n",
       "1               2.0  1.333333            9.0              1.0   \n",
       "1               2.0  1.333333            9.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "2               4.0  3.500000           11.0              1.0   \n",
       "3               4.0  1.888889           23.0              1.0   \n",
       "3               4.0  1.888889           23.0              1.0   \n",
       "3               4.0  1.888889           23.0              1.0   \n",
       "3               4.0  1.888889           23.0              1.0   \n",
       "3               4.0  1.888889           23.0              1.0   \n",
       "3               4.0  1.888889           23.0              1.0   \n",
       "3               4.0  1.888889           23.0              1.0   \n",
       "3               4.0  1.888889           23.0              1.0   \n",
       "3               4.0  1.888889           23.0              1.0   \n",
       "3               4.0  1.888889           23.0              1.0   \n",
       "...             ...       ...            ...              ...   \n",
       "5108            4.0  2.051282            2.0              1.0   \n",
       "5108            4.0  2.051282            2.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5109            5.0  4.000000           15.0              1.0   \n",
       "5110            5.0  3.000000            6.0              1.0   \n",
       "5110            5.0  3.000000            6.0              1.0   \n",
       "5110            5.0  3.000000            6.0              1.0   \n",
       "5110            5.0  3.000000            6.0              1.0   \n",
       "5110            5.0  3.000000            6.0              1.0   \n",
       "5110            5.0  3.000000            6.0              1.0   \n",
       "5111            5.0  3.833333            7.0              1.0   \n",
       "5111            5.0  3.833333            7.0              1.0   \n",
       "5111            5.0  3.833333            7.0              1.0   \n",
       "5111            5.0  3.833333            7.0              1.0   \n",
       "5111            5.0  3.833333            7.0              1.0   \n",
       "5111            5.0  3.833333            7.0              1.0   \n",
       "5111            5.0  3.833333            7.0              1.0   \n",
       "\n",
       "           maxOnlineStatus  avgAvailability  minOnlineStatus  minAvailability  \n",
       "sessionNo                                                                      \n",
       "1                      1.0              1.0              1.0              1.0  \n",
       "1                      1.0              1.0              1.0              1.0  \n",
       "1                      1.0              1.0              1.0              1.0  \n",
       "1                      1.0              1.0              1.0              1.0  \n",
       "1                      1.0              1.0              1.0              1.0  \n",
       "1                      1.0              1.0              1.0              1.0  \n",
       "1                      1.0              1.0              1.0              1.0  \n",
       "1                      1.0              1.0              1.0              1.0  \n",
       "1                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "2                      1.0              1.0              1.0              1.0  \n",
       "3                      1.0              1.0              1.0              1.0  \n",
       "3                      1.0              1.0              1.0              1.0  \n",
       "3                      1.0              1.0              1.0              1.0  \n",
       "3                      1.0              1.0              1.0              1.0  \n",
       "3                      1.0              1.0              1.0              1.0  \n",
       "3                      1.0              1.0              1.0              1.0  \n",
       "3                      1.0              1.0              1.0              1.0  \n",
       "3                      1.0              1.0              1.0              1.0  \n",
       "3                      1.0              1.0              1.0              1.0  \n",
       "3                      1.0              1.0              1.0              1.0  \n",
       "...                    ...              ...              ...              ...  \n",
       "5108                   1.0              1.0              1.0              1.0  \n",
       "5108                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5109                   1.0              1.0              1.0              1.0  \n",
       "5110                   1.0              1.0              1.0              1.0  \n",
       "5110                   1.0              1.0              1.0              1.0  \n",
       "5110                   1.0              1.0              1.0              1.0  \n",
       "5110                   1.0              1.0              1.0              1.0  \n",
       "5110                   1.0              1.0              1.0              1.0  \n",
       "5110                   1.0              1.0              1.0              1.0  \n",
       "5111                   1.0              1.0              1.0              1.0  \n",
       "5111                   1.0              1.0              1.0              1.0  \n",
       "5111                   1.0              1.0              1.0              1.0  \n",
       "5111                   1.0              1.0              1.0              1.0  \n",
       "5111                   1.0              1.0              1.0              1.0  \n",
       "5111                   1.0              1.0              1.0              1.0  \n",
       "5111                   1.0              1.0              1.0              1.0  \n",
       "\n",
       "[45068 rows x 20 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_log_knn['median_20']['X_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17391304, 0.82608696],\n",
       "       [0.17391304, 0.82608696],\n",
       "       [0.52173913, 0.47826087],\n",
       "       ...,\n",
       "       [0.95652174, 0.04347826],\n",
       "       [0.95652174, 0.04347826],\n",
       "       [0.95652174, 0.04347826]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_proba_knn_median_20 = knn_model_median_20.predict_proba(data_log_knn['median_20']['X_test'])\n",
    "predict_proba_knn_median_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a30077d2c9d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_log_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mknn_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mknn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprediction_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodels_knn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mknn_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprediction_knn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    255\u001b[0m             self._tree = KDTree(X, self.leaf_size,\n\u001b[1;32m    256\u001b[0m                                 \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                                 **self.effective_metric_params_)\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'brute'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models_knn = {}\n",
    "for key, value in data_log_knn.items():\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=23)\n",
    "    knn_model.fit(value['X_train'], value['y_train'])\n",
    "    prediction_knn = knn_model.predict(value['X_test'])\n",
    "    models_knn[key] = [knn_model,prediction_knn]\n",
    "#     logistic_model.fit(X_train_lreg, y_train_lreg)\n",
    "#     predictions_logmodel = logistic_model.predict(X_test_lreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data_knn = []\n",
    "column_data_knn = []\n",
    "for key, value in models_knn.items():\n",
    "    index_data_knn.append(key)\n",
    "    column_data_knn.append(value[0].score(data_log_knn[key]['X_test'], data_log_knn[key]['y_test'])*100)\n",
    "#     print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logistic_model.score(X_test_lreg, y_test_lreg)))\n",
    "#     print(classification_report(y_test_lreg,predictions_logmodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_knn = pd.DataFrame(index=index_data_knn, data=column_data_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = df_data_knn.index.values\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = df_data_knn.iloc[:,0].sort_values(ascending=True)\n",
    "\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.8,left=0)\n",
    "# plt.xticks(np.arange(70, 100, step=2))\n",
    "plt.xlim(performance.min()-2, performance.max()+2)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Performance')\n",
    "plt.title('Performance of KNN')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=23, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train_knn,y_train_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_knn = knn.predict(X_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1640 12754]\n",
      " [ 1448 29226]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.11      0.19     14394\n",
      "           1       0.70      0.95      0.80     30674\n",
      "\n",
      "   micro avg       0.68      0.68      0.68     45068\n",
      "   macro avg       0.61      0.53      0.50     45068\n",
      "weighted avg       0.64      0.68      0.61     45068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test_knn,prediction_knn))\n",
    "print(classification_report(y_test_knn,prediction_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating over couple of n_neighbors to test error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "error_rate = []\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40):\n",
    "    \n",
    "    knn_loop = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_loop.fit(X_train_knn,y_train_knn)\n",
    "    prediciton_knn_i = knn_loop.predict(X_test_knn)\n",
    "    error_rate.append(np.mean(prediciton_knn_i != y_test_knn))\n",
    "    print(i, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logisitc Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log_reg = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "models_log_reg = {}\n",
    "for key, value in data_dict.items():\n",
    "    logistic_model = LogisticRegression(solver='lbfgs', multi_class='auto', max_iter=1000)\n",
    "    logistic_model.fit(value['X_train'], value['y_train'])\n",
    "    predictions_logmodel = logistic_model.predict(value['X_test'])\n",
    "    models_log_reg[key] = [logistic_model,predictions_logmodel]\n",
    "#     logistic_model.fit(X_train_lreg, y_train_lreg)\n",
    "#     predictions_logmodel = logistic_model.predict(X_test_lreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data_log_reg = []\n",
    "column_data_log_reg = []\n",
    "for key, value in models_log_reg.items():\n",
    "    index_data_log_reg.append(key)\n",
    "    column_data_log_reg.append(value[0].score(data_log_reg[key]['X_test'], data_log_reg[key]['y_test'])*100)\n",
    "#     print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logistic_model.score(X_test_lreg, y_test_lreg)))\n",
    "#     print(classification_report(y_test_lreg,predictions_logmodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of feature selection: mean_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.52     14394\n",
      "           1       0.77      0.82      0.79     30674\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     45068\n",
      "   macro avg       0.66      0.65      0.66     45068\n",
      "weighted avg       0.70      0.71      0.71     45068\n",
      "\n",
      "[[ 7062  7332]\n",
      " [ 5654 25020]]\n",
      "Type of feature selection: mean_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.50      0.56     14394\n",
      "           1       0.79      0.86      0.82     30674\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     45068\n",
      "   macro avg       0.71      0.68      0.69     45068\n",
      "weighted avg       0.74      0.75      0.74     45068\n",
      "\n",
      "[[ 7195  7199]\n",
      " [ 4164 26510]]\n",
      "Type of feature selection: mean_15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.48      0.55     14394\n",
      "           1       0.78      0.88      0.83     30674\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     45068\n",
      "   macro avg       0.71      0.68      0.69     45068\n",
      "weighted avg       0.74      0.75      0.74     45068\n",
      "\n",
      "[[ 6966  7428]\n",
      " [ 3824 26850]]\n",
      "Type of feature selection: mean_20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.50      0.57     14394\n",
      "           1       0.79      0.88      0.83     30674\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     45068\n",
      "   macro avg       0.73      0.69      0.70     45068\n",
      "weighted avg       0.75      0.76      0.75     45068\n",
      "\n",
      "[[ 7209  7185]\n",
      " [ 3546 27128]]\n",
      "Type of feature selection: mode_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.40      0.46     14394\n",
      "           1       0.75      0.84      0.79     30674\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     45068\n",
      "   macro avg       0.64      0.62      0.62     45068\n",
      "weighted avg       0.68      0.70      0.68     45068\n",
      "\n",
      "[[ 5706  8688]\n",
      " [ 4928 25746]]\n",
      "Type of feature selection: mode_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.45      0.54     14394\n",
      "           1       0.78      0.89      0.83     30674\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     45068\n",
      "   macro avg       0.71      0.67      0.68     45068\n",
      "weighted avg       0.74      0.75      0.73     45068\n",
      "\n",
      "[[ 6539  7855]\n",
      " [ 3476 27198]]\n",
      "Type of feature selection: mode_15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.42      0.52     14394\n",
      "           1       0.77      0.90      0.83     30674\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     45068\n",
      "   macro avg       0.72      0.66      0.67     45068\n",
      "weighted avg       0.74      0.75      0.73     45068\n",
      "\n",
      "[[ 6036  8358]\n",
      " [ 2990 27684]]\n",
      "Type of feature selection: mode_20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.46      0.56     14394\n",
      "           1       0.78      0.91      0.84     30674\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     45068\n",
      "   macro avg       0.75      0.69      0.70     45068\n",
      "weighted avg       0.76      0.77      0.75     45068\n",
      "\n",
      "[[ 6649  7745]\n",
      " [ 2729 27945]]\n",
      "Type of feature selection: median_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.52     14394\n",
      "           1       0.77      0.82      0.79     30674\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     45068\n",
      "   macro avg       0.66      0.65      0.66     45068\n",
      "weighted avg       0.70      0.71      0.71     45068\n",
      "\n",
      "[[ 7045  7349]\n",
      " [ 5613 25061]]\n",
      "Type of feature selection: median_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.49      0.55     14394\n",
      "           1       0.78      0.87      0.82     30674\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     45068\n",
      "   macro avg       0.71      0.68      0.69     45068\n",
      "weighted avg       0.74      0.75      0.74     45068\n",
      "\n",
      "[[ 7015  7379]\n",
      " [ 3976 26698]]\n",
      "Type of feature selection: median_15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.50      0.57     14394\n",
      "           1       0.79      0.88      0.83     30674\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     45068\n",
      "   macro avg       0.72      0.69      0.70     45068\n",
      "weighted avg       0.75      0.76      0.75     45068\n",
      "\n",
      "[[ 7169  7225]\n",
      " [ 3681 26993]]\n",
      "Type of feature selection: median_20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.50      0.58     14394\n",
      "           1       0.79      0.89      0.84     30674\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     45068\n",
      "   macro avg       0.74      0.70      0.71     45068\n",
      "weighted avg       0.76      0.77      0.76     45068\n",
      "\n",
      "[[ 7176  7218]\n",
      " [ 3259 27415]]\n"
     ]
    }
   ],
   "source": [
    "df_data_log_reg = pd.DataFrame(index=index_data_log_reg, data=column_data_log_reg)\n",
    "from sklearn import metrics\n",
    "# for idx, model_gnb in enumerate(models_gnb):\n",
    "for key, value in models_log_reg.items():\n",
    "    print(f'Type of feature selection: {key}')\n",
    "    print(metrics.classification_report(data_dict[key]['y_test'],value[1]))\n",
    "    print(metrics.confusion_matrix(data_dict[key]['y_test'], value[1]))\n",
    "# print(metrics.classification_report(y_test_nab, prediction_gnb))\n",
    "# print(metrics.confusion_matrix(y_test_nab, prediction_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = df_data_log_reg.index.values\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = df_data_log_reg.iloc[:,0].sort_values(ascending=True)\n",
    "\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.8,left=0)\n",
    "# plt.xticks(np.arange(70, 100, step=2))\n",
    "plt.xlim(performance.min()-2, performance.max()+2)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Performance')\n",
    "plt.title('Performance of Logistic Regression')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "models_gnb = {}\n",
    "for key, value in data_dict.items():\n",
    "    model_gnb = GaussianNB()\n",
    "    model_gnb.fit(\n",
    "        value['X_train'],\n",
    "        value['y_train']\n",
    "    )\n",
    "    prediction_gnb = model_gnb.predict(value['X_test'])\n",
    "    models_gnb[key] = [model_gnb,prediction_gnb]\n",
    "#     models_gnb.append([model_gnb,prediction_gnb])\n",
    "# model_gnb = GaussianNB()\n",
    "# model_gnb.fit(\n",
    "#     X_train_nab,\n",
    "#     y_train_nab\n",
    "# )\n",
    "# prediction_gnb = model_gnb.predict(X_test_nab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of feature selection: mean_5\n",
      "Number of mislabeled points out of a total 45068 points : 11981, performance 73.42%\n",
      "Type of feature selection: mean_10\n",
      "Number of mislabeled points out of a total 45068 points : 12621, performance 72.00%\n",
      "Type of feature selection: mean_15\n",
      "Number of mislabeled points out of a total 45068 points : 12647, performance 71.94%\n",
      "Type of feature selection: mean_20\n",
      "Number of mislabeled points out of a total 45068 points : 12054, performance 73.25%\n",
      "Type of feature selection: mode_5\n",
      "Number of mislabeled points out of a total 45068 points : 11981, performance 73.42%\n",
      "Type of feature selection: mode_10\n",
      "Number of mislabeled points out of a total 45068 points : 12560, performance 72.13%\n",
      "Type of feature selection: mode_15\n",
      "Number of mislabeled points out of a total 45068 points : 12680, performance 71.86%\n",
      "Type of feature selection: mode_20\n",
      "Number of mislabeled points out of a total 45068 points : 12129, performance 73.09%\n",
      "Type of feature selection: median_5\n",
      "Number of mislabeled points out of a total 45068 points : 11981, performance 73.42%\n",
      "Type of feature selection: median_10\n",
      "Number of mislabeled points out of a total 45068 points : 12645, performance 71.94%\n",
      "Type of feature selection: median_15\n",
      "Number of mislabeled points out of a total 45068 points : 12660, performance 71.91%\n",
      "Type of feature selection: median_20\n",
      "Number of mislabeled points out of a total 45068 points : 12049, performance 73.26%\n"
     ]
    }
   ],
   "source": [
    "index_data_df = []\n",
    "column_data_df = []\n",
    "for key, value in models_gnb.items():\n",
    "    print(f'Type of feature selection: {key}')\n",
    "    print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "          .format(\n",
    "              data_dict[str(key)]['X_test'].shape[0],\n",
    "              (data_dict[key]['y_test'] != value[1]).sum(),\n",
    "              100*(1-(data_dict[key]['y_test'] != value[1]).sum()/data_dict[key]['y_test'].shape[0])\n",
    "    ))\n",
    "    index_data_df.append(key)\n",
    "    column_data_df.append(100*(1-(data_dict[key]['y_test'] != value[1]).sum()/data_dict[key]['y_test'].shape[0]))\n",
    "    \n",
    "#     print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "#       .format(\n",
    "#           X_test_nab.shape[0],\n",
    "#           (y_test_nab != prediction_gnb).sum(),\n",
    "#           100*(1-(y_test_nab != prediction_gnb).sum()/y_test_nab.shape[0])\n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_5       73.415727\n",
       "mean_10      71.995651\n",
       "mean_15      71.937960\n",
       "mean_20      73.253750\n",
       "mode_5       73.415727\n",
       "mode_10      72.131002\n",
       "mode_15      71.864738\n",
       "mode_20      73.087335\n",
       "median_5     73.415727\n",
       "median_10    71.942398\n",
       "median_15    71.909115\n",
       "median_20    73.264844\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_naive_b = pd.DataFrame(index=index_data_df, data=column_data_df)\n",
    "df_data_naive_b.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of feature selection: mean_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.23      0.36     14394\n",
      "           1       0.73      0.97      0.83     30674\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     45068\n",
      "   macro avg       0.76      0.60      0.59     45068\n",
      "weighted avg       0.75      0.73      0.68     45068\n",
      "\n",
      "[[ 3318 11076]\n",
      " [  905 29769]]\n",
      "Type of feature selection: mean_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.19      0.30     14394\n",
      "           1       0.72      0.97      0.82     30674\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     45068\n",
      "   macro avg       0.73      0.58      0.56     45068\n",
      "weighted avg       0.72      0.72      0.66     45068\n",
      "\n",
      "[[ 2749 11645]\n",
      " [  976 29698]]\n",
      "Type of feature selection: mean_15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.22      0.33     14394\n",
      "           1       0.72      0.96      0.82     30674\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     45068\n",
      "   macro avg       0.71      0.59      0.58     45068\n",
      "weighted avg       0.71      0.72      0.67     45068\n",
      "\n",
      "[[ 3114 11280]\n",
      " [ 1367 29307]]\n",
      "Type of feature selection: mean_20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.29      0.41     14394\n",
      "           1       0.74      0.94      0.83     30674\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     45068\n",
      "   macro avg       0.72      0.61      0.62     45068\n",
      "weighted avg       0.73      0.73      0.69     45068\n",
      "\n",
      "[[ 4109 10285]\n",
      " [ 1769 28905]]\n",
      "Type of feature selection: mode_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.23      0.36     14394\n",
      "           1       0.73      0.97      0.83     30674\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     45068\n",
      "   macro avg       0.76      0.60      0.59     45068\n",
      "weighted avg       0.75      0.73      0.68     45068\n",
      "\n",
      "[[ 3318 11076]\n",
      " [  905 29769]]\n",
      "Type of feature selection: mode_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.20      0.31     14394\n",
      "           1       0.72      0.97      0.83     30674\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     45068\n",
      "   macro avg       0.73      0.58      0.57     45068\n",
      "weighted avg       0.72      0.72      0.66     45068\n",
      "\n",
      "[[ 2872 11522]\n",
      " [ 1038 29636]]\n",
      "Type of feature selection: mode_15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.22      0.33     14394\n",
      "           1       0.72      0.95      0.82     30674\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     45068\n",
      "   macro avg       0.70      0.59      0.58     45068\n",
      "weighted avg       0.71      0.72      0.67     45068\n",
      "\n",
      "[[ 3142 11252]\n",
      " [ 1428 29246]]\n",
      "Type of feature selection: mode_20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.28      0.40     14394\n",
      "           1       0.74      0.94      0.83     30674\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     45068\n",
      "   macro avg       0.71      0.61      0.61     45068\n",
      "weighted avg       0.72      0.73      0.69     45068\n",
      "\n",
      "[[ 4082 10312]\n",
      " [ 1817 28857]]\n",
      "Type of feature selection: median_5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.23      0.36     14394\n",
      "           1       0.73      0.97      0.83     30674\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     45068\n",
      "   macro avg       0.76      0.60      0.59     45068\n",
      "weighted avg       0.75      0.73      0.68     45068\n",
      "\n",
      "[[ 3318 11076]\n",
      " [  905 29769]]\n",
      "Type of feature selection: median_10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.19      0.30     14394\n",
      "           1       0.72      0.97      0.82     30674\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     45068\n",
      "   macro avg       0.72      0.58      0.56     45068\n",
      "weighted avg       0.72      0.72      0.66     45068\n",
      "\n",
      "[[ 2770 11624]\n",
      " [ 1021 29653]]\n",
      "Type of feature selection: median_15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.22      0.33     14394\n",
      "           1       0.72      0.95      0.82     30674\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     45068\n",
      "   macro avg       0.71      0.59      0.58     45068\n",
      "weighted avg       0.71      0.72      0.67     45068\n",
      "\n",
      "[[ 3142 11252]\n",
      " [ 1408 29266]]\n",
      "Type of feature selection: median_20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.29      0.41     14394\n",
      "           1       0.74      0.94      0.83     30674\n",
      "\n",
      "   micro avg       0.73      0.73      0.73     45068\n",
      "   macro avg       0.72      0.61      0.62     45068\n",
      "weighted avg       0.72      0.73      0.69     45068\n",
      "\n",
      "[[ 4146 10248]\n",
      " [ 1801 28873]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# for idx, model_gnb in enumerate(models_gnb):\n",
    "for key, value in models_gnb.items():\n",
    "    print(f'Type of feature selection: {key}')\n",
    "    print(metrics.classification_report(data_dict[key]['y_test'],value[1]))\n",
    "    print(metrics.confusion_matrix(data_dict[key]['y_test'], value[1]))\n",
    "# print(metrics.classification_report(y_test_nab, prediction_gnb))\n",
    "# print(metrics.confusion_matrix(y_test_nab, prediction_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "71.86473772965296\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = df_data_naive_b.index.values\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = df_data_naive_b.iloc[:,0].sort_values(ascending=True)\n",
    "\n",
    "print(str(y_pos))\n",
    "print(performance.min())\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.8,left=0)\n",
    "# plt.xticks(np.arange(70, 100, step=2))\n",
    "plt.xlim(performance.min()-2, performance.max()+2)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Performance')\n",
    "plt.title('Performance in Naive Bayes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_svm = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/marianbauersachs/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "models_svc = {}\n",
    "for key, value in data_svm.items():\n",
    "    model_svc = SVC()\n",
    "    model_svc.fit(\n",
    "        value['X_train'],\n",
    "        value['y_train']\n",
    "    )\n",
    "    prediction_svc = model_svc.predict(value['X_test'])\n",
    "    models_svc[key] = [model_svc,prediction_svc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data_svc = []\n",
    "column_data_svc = []\n",
    "for key, value in models_svc.items():\n",
    "    index_data_svc.append(key)\n",
    "    column_data_svc.append(100*(1-(data_svm[key]['y_test'] != value[1]).sum()/data_svm[key]['y_test'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = data_svm.index.values\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = data_svm.iloc[:,0].sort_values(ascending=True)\n",
    "\n",
    "print(str(y_pos))\n",
    "print(performance.min())\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.8,left=0)\n",
    "# plt.xticks(np.arange(70, 100, step=2))\n",
    "plt.xlim(performance.min()-2, performance.max()+2)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Performance')\n",
    "plt.title('Performance in Naive Bayes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtc = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models_dtc = {}\n",
    "for key, value in data_dtc.items():\n",
    "    model_dtree = DecisionTreeClassifier()\n",
    "    model_dtree.fit(\n",
    "        value['X_train'],\n",
    "        value['y_train']\n",
    "    )\n",
    "    prediction_dtc = model_dtree.predict(value['X_test'])\n",
    "    models_dtc[key] = [model_dtree,prediction_dtc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data_dtc = []\n",
    "column_data_dtc = []\n",
    "for key, value in models_dtc.items():\n",
    "    index_data_dtc.append(key)\n",
    "    column_data_dtc.append(100*(1-(data_dtc[key]['y_test'] != value[1]).sum()/data_dtc[key]['y_test'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_dtc = pd.DataFrame(index=index_data_dtc, data=column_data_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "71.68279044998668\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-b583500bf352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# plt.xticks(np.arange(70, 100, step=2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperformance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "objects = df_data_dtc.index.values\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = df_data_dtc.iloc[:,0].sort_values(ascending=True)\n",
    "\n",
    "print(str(y_pos))\n",
    "print(performance.min())\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.8,left=0)\n",
    "# plt.xticks(np.arange(70, 100, step=2))\n",
    "plt.xlim(performance.min()-2, performance.max()+2)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Performance')\n",
    "plt.title('Performance in Naive Bayes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dtc_2 =  DecisionTreeClassifier()\n",
    "model_dtc_2.fit(\n",
    "    data_dtc['median_20']['X_train'],\n",
    "    data_dtc['median_20']['y_train']\n",
    ")\n",
    "prediction_dtc_2 = model_dtc_2.predict(data_dtc['median_20']['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dtc_2 = model_dtc_2.predict(data_rfm['median_20']['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.06159581077482"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_dtc_2 = 100*(1-(data_dtc['median_20']['y_test'] != prediction_dtc_2[1]).sum()/data_dtc['median_20']['y_test'].shape[0])\n",
    "performance_dtc_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rfm = get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5ea94152a745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     model_rfm.fit(\n\u001b[1;32m      6\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     \u001b[0mprediction_rfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 335\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    363\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models_rfm = {}\n",
    "for key, value in data_rfm.items():\n",
    "    model_rfm =  RandomForestClassifier(n_estimators=600)\n",
    "    model_rfm.fit(\n",
    "        value['X_train'],\n",
    "        value['y_train']\n",
    "    )\n",
    "    prediction_rfm = model_rfm.predict(value['X_test'])\n",
    "    models_rfm[key] = [model_rfm,prediction_rfm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data_rfm = []\n",
    "column_data_rfm = []\n",
    "for key, value in models_rfm.items():\n",
    "    index_data_rfm.append(key)\n",
    "    column_data_rfm.append(100*(1-(data_rfm[key]['y_test'] != value[1]).sum()/data_rfm[key]['y_test'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = data_rfm.index.values\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = data_rfm.iloc[:,0].sort_values(ascending=True)\n",
    "\n",
    "print(str(y_pos))\n",
    "print(performance.min())\n",
    "plt.barh(y_pos, performance, align='center', alpha=0.8,left=0)\n",
    "# plt.xticks(np.arange(70, 100, step=2))\n",
    "plt.xlim(performance.min()-2, performance.max()+2)\n",
    "plt.yticks(y_pos, objects)\n",
    "plt.xlabel('Performance')\n",
    "plt.title('Performance in Naive Bayes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 20 and input n_features is 15 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5ab7b8e1f1fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_rfm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'median_20'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprediction_rfm_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_rfm_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    362\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    385\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 20 and input n_features is 15 "
     ]
    }
   ],
   "source": [
    "model_rfm_2 =  RandomForestClassifier(n_estimators=600)\n",
    "model_rfm_2.fit(\n",
    "    data_rfm['median_20']['X_train'],\n",
    "    data_rfm['median_20']['y_train']\n",
    ")\n",
    "prediction_rfm_2 = model_rfm_2.predict(value['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_rfm_2 = model_rfm_2.predict(data_rfm['median_20']['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.06159581077482"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_rfm_2 = 100*(1-(data_rfm['median_20']['y_test'] != prediction_rfm_2[1]).sum()/data_rfm['median_20']['y_test'].shape[0])\n",
    "performance_rfm_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
